Bert pro analýzu sentimentu:
- použiju berta z huggingface a dodám jednu fully connected vrstvu který šoupnu oanotovaný data
- potřeba tam ale strkat data správně otagovaný jako to dělal Bert (run_tf_glue - finetunuje berta na sentimenty)
    - má tam i tokenizer (jinej než si představuju) - jenom to rozsekává na subwords podle těch dat, na kterejch se to trénovalo
    (všechny nějaká subsekvence, který to někdy vidělo)

SMO
- SMO (M pošle linky). Stanford k tomu má učebnici a lecture

Nemáme
- zapojení slovníku

Chceme měřit:
- bez slovníku/se slovníkem
- s bertem (jen embeddingy co lezou z Berta - jako elmo) = self.model
- fine tunning berta (tady je to průměrování - ono to rozseká na menší divný kusy a já je pak zprůměruju a strčim do toho,
co už mám teď napsaný (to chce jen jedno to číslo) - tf.math.segment_mean) - k tomu potřebuju ještě vědět který kousky jsou
k jakýmu slovu = self.outer_model (1 epocha, malý learning rate)
- jenom berta bez všech těch věcí (je třeba k tomu dát character level embeddingy <- ty už se počítaj (připojim k tomu co vypadne z toho berta) )

text:

    tagger, lemmatizace
        - rnn,lstm -> embeddingy, (word2vec) -> bert (rozdíl proti předchozímu, nepotřebuju supervised data)
    sentiment
        - zase 3 výsledky (naměříme sami)
        - knížka (Veselovská)
    (syntax - spíš asi ne)
        - 2 datasty - pdt, UD
    NER
        -

analýza chyb

appka

slovník - opíšu z toho starýho

embedingy přidat do datasetu! a ukládat
musí to být po batchích

