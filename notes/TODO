================================================================================
PHASE 1
================================================================================
X udelat maly trenovaci set
X pridat smoothing
    X pridat k labelum
        X v tom starem je to implementovano
        X potrebuju to mit vzdycky stejne pro ruzne batche (ten one hot) NE
        X potrebuju mit v grafu spravnou velikost toho vysledku(?) NE
        X upravit i v evaluate!
    X upravit loss function na CategoricalCrossentropy

X dodělat predikci
X elmo

X pridat slovnik
    X pridat do metrik pole
    X pridat do metrik vysledky
    X pocitat vysledky se slovnikem - v evaluate batch
    X opravit slovník
        X prepsat do eval_batch
        X opravit pocitani predikci


X pridat berta jen embeddingy + ukladat predpoctene

    X vytvorit model a tokenizer - v dataset u pocitani
    X vracet vysledky v morpho_dataset next batch
    X ulozit predpoctene vysledky
    X predavat argument o bertu k datasetu
    X pridat do inputu modelu stejne jako embeddings co tam jsou
    X predavat v metodach do grafu
    X pridat bert do dev a test datasetu
    X pridat unk a pad
        X kam?
        X pridat
    X jsou not found jen paddings a unknown? (asi ano!)
    X ukladat v datasetu primo embeddingy
    X zajistit spravne indexovani
    X zmenit train a evaluate
    X do argumentu bert dát jmeno modelu
    X prejmenovat soubory

X oprava a provereni kodu
    X opravit embeddings po vetach
        X prepsat vypocet
        X prepsat nacitani
        X prepsat ukladani
        X prepsat pouzivani train a evaluate
    X proverit:
        X bez label smoothingu
        X s label smoothingem
        X verze před dictionary, kde bylo těch 96 (v commitu 394f125b43b25045945eb78df4f7ab852fa08e84 jsem opravovala loss function)
        X s bertem bez label smoothingu
        X s bertem a label smoothingem

================================================================================
PHASE 2
================================================================================
X pridat berta poradne a prumerovat embeddingy :(


X sentiment s bertem bez preprocessingu
    X vytvorit model

================================================================================
PHASE 3
================================================================================
X text
    X nastudovat vše do Milana
    X doplnit historii NLP
    - dopsat plán do mindenote
        - pro část experimenty
        - pro diskuzi rozhodnutí - lze už teď připravit minimálně otázky
        - dopsat implementaci
- kód
    X zprovoznit i finetunning
    - pridat accuracy pro dvojice factors
    - připravit skript na experimenty dle poznámek
        - sentiment
        X tag+lemma
            X v sloupcích budou tagraw, taglemma atd..
                i vygrepování
                i v řádcích jednotlivé modely nějak smysluplně seřazené a pojemnované bertmodel, lr type, epocha, ktere vrstvy
                i oddělené tabulátorem
                X pridat do souboru
                i osetrit ze sude radky je ten vypis
    i upravit vypisovani vysledku aby bylo tak hezké jak chci
    - pustit skript na vše

    - připravit skript co načte model a pak bude interaktivně vracet odpovědi -  v colabu
        - sentiment
        - tag+lemma

- experimenty tagging a lemmatizace
    i baseline bez ls
    i baseline s ls
    i embeddingy
    i finetunning
        i 5 lr x 1-4 epochy (5e-5 3e-5 2e-5 8e-6 1e-6)
            i batch až 64
            i batch 16
        i různé lr pro berta a vrstvy nad ním
        i lr warmup a decay
        ? brát skoro všechny vrstvy x 4 vrstvy x prumeorovat ci konkatenovat
        i vše pustit na roberta, bert, slavicbert,
        - BERT český, electra česká
    - bert bez pipeline
        - tagging
        - lemmatizace
        , lr warmup a decay
        - brát skoro všechny vrstvy x 4 vrstvy x prumeorovat ci konkatenovat
        - vše pustit na roberta, bert, distillbert, slavicbert, BERT český
    X  UPRAVIT COMMANDS ABY TO MENILO MODELY
- electra
    X napsat samostatný tokenizer na trénování
    X rozbalit data
    X projit všechny argumenty na trenovani
    X precist elektra jestli resi ktery tokenizer pouzit
    X prikaz na spusteni tokenizeru
    X tokenizer encoding
    - vybrat ctvrtinu a splacnout dohromady
    - pustit

- sentiment - kód
    X prozkoumat data - poměry neutral/positive/negative
    - pridat vyhodnocení na dev
    - udelat trenovani jen nekterych vrstev ci warmup decay
    - udelat cross validaci
    x vyřešit že airlines nemá neutrál
    - počítat F1, precision, recall (pro jednotlivé třídy) (nebo confusion matrix)
    - modely pro jednotlivé datasety
    - české SOTA výsledky
    - zapracovat ještě mall a csfd (mám odkaz)
    - zkusit překlad do angličtiny
    - vše pustit na
        i roberta,
        i bert,
        - distillbert,
        - slavicbert,
        - BERT czech,
    - s angličtinou:
        - Zero-shot
        - monolingual,
        - multilingual training
        - bez trénování jen embeddingy
        - pomer dat

================================================================================
PHASE 4
================================================================================
- text
    - theory
    - experimenty
        - pripravit tabulky
        - popsat moznosti hyperparametru
    - implementace
    - pořádek v gitu
    - colab notebook
        - sentiment
        - tags and lemmas
            - namapovat checkpoints na informace o modelech

- experimenty
    - tags,lemmas standard
        X upravit checkpoints, abych měla všechny a věděla k čemu patří (vyresi se spustenim vseho)
        - pustit
        X využit expe argument (netreba)
        - do grepu pridat i join accuracy
    - bert simple
        - lr warmup a decay
        - vše pustit na roberta, bert, distillbert, slavicbert, BERT český
        - trenovat jen poslední vrstvu a pak vše
    - sentiment
        - s angličtinou:
        - Zero-shot
        - monolingual,
        - multilingual training
        - bez trénování jen embeddingy
        - pomer dat

- implementace
    - slavic bert obecne vyresit nacitani
    - sentiment
        - pridat vyhodnocení na dev
        - udelat trenovani jen nekterych vrstev ci warmup decay
        - udelat cross validaci
        - počítat F1, precision, recall (pro jednotlivé třídy) (nebo confusion matrix)
        - modely pro jednotlivé datasety
        - české SOTA výsledky
        - zkusit překlad do angličtiny
        - opšny
            - s angličtinou:
            - Zero-shot
            - monolingual,
            - multilingual training
            - bez trénování jen embeddingy
            - pomer dat

        - datasety
            - mall
            - csfd
            X facebook
    - morpho_tagger_2
        X accuracy dohromady
        - uložit obrazek jednou
    - bert_finetunning_simple
        X accuracy dohromady
        X lemmatizace
        X trenovani jen posledni vrstva a zbytek (+ opšny na to)
        ? fine lr
        ? warmup a decay
        X label smoothing
        X cle
        X token dropout
        ? word dropout
    - electra
        X vybrat ctvrtinu
        - splacnout dohromady vety v dokumentu
            X ctvrtina
            - pustit na vse
        - zjistit kolik pameti
        X upravit sliding window opšnu





