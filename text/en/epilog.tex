\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}
\label{chap:concl}
In this thesis, we implemented Czech \acrlong{pos} tagging, lemmatization and sentiment analysis with the usage of \acrlong{bert}-like architectures. We achieved \acrlong{sota} results in tagging (accuracy 98.57\%) and lemmatization (accuracy 99.00\%) and joint accuracy of these two tasks 98.19\%, which presents the error reduction by more than 32\% compared to previous public model \citep{Strakova}. We presents new \acrshort{sota} in sentiment analysis on all three used datasets -- \textit{mall}, \textit{csfd}, \textit{facebook}, namely 27\% error reduction on facebook dataset. We also explored various training techniques and showed the good performance of static embeddings compared to any further training of BERT models. This thesis also examines types of errors BERT helps to solve. All code, text and best models are publicly available on GitHub: \url{https://github.com/flower-go/DiplomaThesis}
%TODO udelat hezkou tu repo
%TODO dodelat nacitani tech model≈Ø
%TODO porvnani s public modelem 95.55% tag accuracy, 97.86% lemma accuracy and 95.06% o 32% tagging, o 46% lemmatization a 36% both 
