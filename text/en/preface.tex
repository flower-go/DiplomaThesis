\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
This work aims to improve selected \acrfull{nlp} tasks for Czech with the use of recently published \acrlong{sota} techniques, namely with the incorporation of deep neural networks. In recent years, neural networks have achieved great success in many areas, e.g., computer vision or speech recognition, or marketing, and they have successfully fought their way from academic research to all areas of industry. 
\par
People think and communicate in natural languages. They express their opinions, share information and feelings, or persuade others about their ideas, all in natural languages. In the current era of digital technologies, all this information (sadly even information people do not share consciously and with awareness of potential risks) are available online. The amount of data is so enormous that it is not in human power to sort and use them, and that is when \acrshort{nlp} is a necessary step for further processing by computers. For these reasons, many \acrshort{nlp} use cases exist, for example extracting opinions about new products (e.g., via sentiment analysis or topic modeling), using chatbots instead of paying employees in a call center, voice assistance for the disabled, filtering spam from email, summarizing the content of papers or finding answers in texts. \par
This work applies the most successful \gls{nlp} methods (transfer learning of multilingual bidirectional language model) of recent years to Czech \acrlong{nlp} tasks. Such models are typically trained on a large amount of data (multilingual or monolingual). This work uses two pre-trained multilingual models (BERT\citep{Devlin2019} and XLM-RoBERTa \citep{Conneau2019}), that were trained in many languages including Czech, and a monolingual Czech variant of RoBERTa called RobeCzech \citep{Straka2021}. Selected tasks are tagging, lemmatization, and sentiment analysis. Tagging and lemmatization represent syntax analysis and are typically necessary in more complex linguistic analysis tasks of many types. Sentiment analysis belongs into the semantic part of \acrshort{nlp}, and the output is readably and usable even for the end-user -- it indicates whether the author of the given text expresses a positive or negative opinion. \par
Tasks were chosen from both semantics and syntax to show how pre-trained multilingual language models can help with different types of \gls{nlp} tasks. This work builds directly on previous work on tagging and lemmatization contextualized embeddings \citep{straka2019czech} and uses existing datasets for all tasks and aims to state new \acrfull{sota} results.
\par
The text of the work is divided into seven chapters. \hyperref[chap:theandme]{First chapter} presents theoretical background in \acrshort{nlp} and used \acrfull{ai} methods. This quite general chapter is followed by a thorough description of implemented tasks, each in its own separate chapter ( \hyperref[chap:tag]{Lemmatization and \acrlong{pos} tagging},  \hyperref[chap:sent]{Sentiment analysis},  \hyperref[chap:mod]{Language modelling}). Description of each task includes its definition, previous work, state-of-the-art results, methods applied in this work, and their results. Implementation details like code overview, third-party libraries, technical problems, and their solution can be found in chapter \ref{chap:impl}.
For personal examination and exploration of presented models serves user documentation of attached models in chapter \ref{chap:userdoc} and text is closed by a discussion about results (chapter \ref{chap:diss}) and a \hyperref[chap:concl]{conclusion} with future work proposals.

